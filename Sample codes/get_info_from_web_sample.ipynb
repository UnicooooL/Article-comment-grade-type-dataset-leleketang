{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee728b61",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255f7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import requests \n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff030a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fake-useragent in d:\\anaconda\\lib\\site-packages (1.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (d:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d41ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d231e03",
   "metadata": {},
   "source": [
    "## set up the links and IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79773b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = 'https://www.leleketang.com/zuowen/'\n",
    "\n",
    "urlArray = [\n",
    "  #'list30-0-0-1-1.shtml', \n",
    "  #'clist0-0-0-1-1.shtml',\n",
    "  'list20-0-0-1-1.shtml'\n",
    "  #'list10-0-0-1-1.shtml'\n",
    "]\n",
    "\n",
    "# define different user agents information\n",
    "user_agent_list = [\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0\",\n",
    "                   \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Version/13.1.2 Safari/537.36\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36 Edg/93.0.961.38\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; AS; rv:11.0) like Gecko\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36 OPR/78.0.4093.231\",\n",
    "                   \"Mozilla/5.0 (Linux; Android 11; Pixel 3 XL) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Mobile Safari/537.36\",\n",
    "                   \"Mozilla/5.0 (Android 11; Mobile; rv:93.0) Gecko/93.0 Firefox/93.0 SamsungBrowser/17.0\"\n",
    "                   \"Mozilla/5.0 (Windows Phone 10.0; Android 6.0.1; Microsoft; RM-1152) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Mobile Safari/537.36 Edge/40.15254.547\",\n",
    "                   \"Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; AS; rv:11.0) like Gecko\",\n",
    "                   \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/88.0.705.50 Safari/537.36\",\n",
    "                    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_5_2) AppleWebKit/537.36 (KHTML, like Gecko) Version/14.1.2 Safari/537.36\",\n",
    "                   \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36 Edg/114.0.1823.82\"\n",
    "                    ]\n",
    "\n",
    "# define different ip addresses\n",
    "ip_list=[                       \n",
    "        '118.70.144.77:3128',\n",
    "        '113.200.105.45:8080'\n",
    "    ]\n",
    "\n",
    "# from where\n",
    "referer_list=[\n",
    "            'https://www.sogou.com/',\n",
    "            'https://www.baidu.com/'\n",
    "        ]\n",
    "\n",
    "# change ip\n",
    "ip=random.choice(ip_list)\n",
    "proxy_ip = 'http://' + ip\n",
    "proxy_ips = 'https://' + ip\n",
    "proxy = {'https': proxy_ips, 'http': proxy_ip}\n",
    "\n",
    "urls = []\n",
    "evaluate = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ddaf2",
   "metadata": {},
   "source": [
    "## Define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02237047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request html according to url\n",
    "def query(url):\n",
    "    html = requests.get(url=url, headers=headers)\n",
    "    page = html.content.decode('utf-8', 'ignore')\n",
    "    return BeautifulSoup(page, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20a2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate(page):\n",
    "    # Get title links\n",
    "    compositions_rating_5 = page.find_all('a', class_ = 'ellipsis item_rating_5')\n",
    "    compositions_rating_4 = page.find_all('a', class_ = 'ellipsis item_rating_4')\n",
    "    compositions_rating_3 = page.find_all('a', class_ = 'ellipsis item_rating_3')\n",
    "    compositions_rating_2 = page.find_all('a', class_ = 'ellipsis item_rating_2')\n",
    "\n",
    "    compositions = compositions_rating_5 + compositions_rating_4 + compositions_rating_3 + compositions_rating_2\n",
    "\n",
    "    # Visit all papers in current page and store\n",
    "    for title in compositions:\n",
    "        compositionPage = query(baseUrl + title['href'])\n",
    "        \n",
    "        # Get the article rating score\n",
    "        name_orig = compositionPage.find('h2', class_ = 'cp_htitle')\n",
    "        if(name_orig):\n",
    "            name = name_orig.get_text()\n",
    "        else:\n",
    "            name = \"N/A\"\n",
    "        \n",
    "        # Get the article rating score\n",
    "        score = compositionPage.find('div', class_ = 'cp_rating rating5')\n",
    "        if(score):\n",
    "            rating = \"优\"\n",
    "        else:\n",
    "            score = compositionPage.find('div', class_ = 'cp_rating rating4')\n",
    "            if(score):\n",
    "                rating = \"优\"\n",
    "            else:\n",
    "                score = compositionPage.find('div', class_ = 'cp_rating rating2')\n",
    "                if(score):\n",
    "                    rating = \"中\"\n",
    "                else:\n",
    "                    score = compositionPage.find('div', class_ = 'cp_rating rating3')\n",
    "                    if(score):\n",
    "                        rating = \"良\"\n",
    "                    else:\n",
    "                        rating = \"差\"\n",
    "        \n",
    "          # Get the comment\n",
    "        for tag in compositionPage.find_all('div', class_ = \"cp_comment\"):\n",
    "            comment = tag.find('p').get_text()\n",
    "            # Get all content paragraphs and combine them\n",
    "            content_paragraphs = compositionPage.find_all('div', class_='cp_content')\n",
    "            content_parts = []\n",
    "            for paragraph in content_paragraphs:\n",
    "                for t in paragraph.find_all(['p']):\n",
    "                    content_parts.append(t.get_text())\n",
    "            content = ' '.join(content_parts)\n",
    "            # store the tags\n",
    "            cat_tot = compositionPage.find_all('div', class_='com_tag')\n",
    "            cat_parts = []\n",
    "            counter = 0\n",
    "            for cat in cat_tot:\n",
    "                for c in cat.find_all(['a']):\n",
    "                    if (counter != 0):\n",
    "                        cat_parts.append(\"/\")  # as a splitter\n",
    "                    cat_parts.append(c.get_text())  # append the content\n",
    "                    counter += 1  # cnt + 1\n",
    "            categories = ' '.join(cat_parts)\n",
    "                \n",
    "            # Write all information to the CSV file in the same row\n",
    "            row = [baseUrl + title['href'], name, rating, categories, content, comment]\n",
    "            if(row == None):\n",
    "                print(\"Not reading at all!\")\n",
    "                return False\n",
    "            csvwrite.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f5e68",
   "metadata": {},
   "source": [
    "## Set up the file path and get information from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e54251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path\n",
    "file_path = 'Your/path/goes/here.csv'\n",
    "\n",
    "# Check if the file already exists\n",
    "if os.path.isfile(file_path):\n",
    "    # If the file exists, delete it\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Create a new file\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    csvwrite = csv.writer(file)\n",
    "    # Add column headers\n",
    "    csvwrite.writerow(['Composition Link', 'Title', 'Score', 'Category', 'Article Context', 'Comment'])\n",
    "    #pass  # No need to write anything, just pass\n",
    "\n",
    "# Read the file\n",
    "f = open(file_path, mode = \"w\", encoding = \"utf-8\", newline = \"\")  # w: writter mode, encoding: use utf-8 code to read character\n",
    "csvwrite = csv.writer(f)  # create a csv writter object\n",
    "\n",
    "\n",
    "# Define the headers; information from inspection of https://www.leleketang.com/ \n",
    "headers = {\n",
    "    'User-Agent' : ua.random, #random.choice(user_agent_list),\n",
    "    #'Accept-Language':'zh-CN,zh;q=0.9', \n",
    "    'cookie' : \"gs_browser=pc; gs_browse_mode=desktop; PHPSESSID=dedb3d57ff60b15d26d25b0631e76ac4; Hm_lvt_8296a32ce52c7db4820be505c8738193=1689086848; gs_anony=O%3A4%3A%22User%22%3A33%3A%7Bs%3A2%3A%22id%22%3Bi%3A1172426712%3Bs%3A6%3A%22fromId%22%3Bs%3A5%3A%22anony%22%3Bs%3A5%3A%22snsId%22%3Bi%3A0%3Bs%3A8%3A%22nickname%22%3Bs%3A16%3A%22%E6%B8%B8%E5%AE%A21172426712%22%3Bs%3A6%3A%22gender%22%3Bi%3A0%3Bs%3A6%3A%22avatar%22%3Bs%3A23%3A%22%2Flogin%2Fimage%2Fanony2.png%22%3Bs%3A5%3A%22space%22%3Bs%3A0%3A%22%22%3Bs%3A5%3A%22email%22%3Bs%3A0%3A%22%22%3Bs%3A6%3A%22mobile%22%3Bs%3A0%3A%22%22%3Bs%3A8%3A%22realName%22%3Bs%3A0%3A%22%22%3Bs%3A8%3A%22location%22%3Bs%3A0%3A%22%22%3Bs%3A5%3A%22brief%22%3Bs%3A0%3A%22%22%3Bs%3A9%3A%22signature%22%3Bs%3A0%3A%22%22%3Bs%3A10%3A%22createTime%22%3Bs%3A0%3A%22%22%3Bs%3A4%3A%22fans%22%3Bi%3A0%3Bs%3A7%3A%22follows%22%3Bi%3A0%3Bs%3A8%3A%22articles%22%3Bi%3A0%3Bs%3A4%3A%22role%22%3Bi%3A0%3Bs%3A8%3A%22roleName%22%3Bs%3A0%3A%22%22%3Bs%3A6%3A%22skinId%22%3Bi%3A0%3Bs%3A8%3A%22birthday%22%3Bs%3A0%3A%22%22%3Bs%3A10%3A%22locationId%22%3Bi%3A0%3Bs%3A9%3A%22famillyId%22%3Bi%3A0%3Bs%3A6%3A%22visits%22%3Bi%3A0%3Bs%3A13%3A%22lastVisitTime%22%3BN%3Bs%3A4%3A%22days%22%3Bi%3A0%3Bs%3A8%3A%22lastDays%22%3Bi%3A0%3Bs%3A5%3A%22coins%22%3Bi%3A0%3Bs%3A4%3A%22gems%22%3Bi%3A0%3Bs%3A11%3A%22experiences%22%3Bi%3A0%3Bs%3A19%3A%22current_experiences%22%3Bi%3A0%3Bs%3A5%3A%22level%22%3Bi%3A0%3Bs%3A6%3A%22awards%22%3Bi%3A0%3B%7D; state=https%3A%2F%2Fwww.leleketang.com%2Flogin%2Fverify.php%3Fstate%3D%2Fzuowen%2Flist30-0-0-96-1.shtml; gs_pass=35266162-e4636387f88ee05f6e39f06195741523; Hm_lpvt_8296a32ce52c7db4820be505c8738193=1689125438\",\n",
    "    # Setting jump from where\n",
    "    'Connection': 'close',\n",
    "    'referer': random.choice(referer_list),\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, url in enumerate(urlArray):\n",
    "    homePage = query(baseUrl + url)\n",
    "\n",
    "  # Get the total page count for four classes each\n",
    "    for tag in homePage.find_all('div', class_ = 'p_pager_brief'):\n",
    "        pageCount = int(tag.find('span').get_text().split('/')[1])\n",
    "\n",
    "        with ThreadPoolExecutor(100) as t:\n",
    "        # Loop through all the pages on current class\n",
    "          for tag in range(0, pageCount):\n",
    "            page = query(baseUrl + url[:11] + str(tag+1) + url[-8:])\n",
    "            get_evaluate(page)\n",
    "            cnt = tag\n",
    "            time.sleep(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c68f54",
   "metadata": {},
   "source": [
    "## Open file to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98039cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"Your/path/goes/here.csv\"\n",
    "import csv\n",
    "with open(file_dir,'r', encoding = 'UTF-8') as csvfile:\n",
    "    data_reader = csv.reader(csvfile)\n",
    "\n",
    "    data_orig = []\n",
    "    for row in data_reader:\n",
    "        data_orig.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2acfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orig[1675]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
